{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## learn NLP from scratch\n",
    "Enviroment: kaggle_python docker_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load datasets from kaggle toxic comment classifier compitition\n",
    "train = pd.read_csv('./DATASETS/train.csv')\n",
    "test = pd.read_csv('./DATASETS/test.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \n",
    "                \"threat\", \"insult\", \"identity_hate\"]\n",
    "y = train[list_classes].values\n",
    "list_sentences_train = train[\"comment_text\"]\n",
    "list_sentences_test = test[\"comment_text\"]\n",
    "list_sentences_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown #a corpus contributed by Brown University\n",
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Explanation',\n",
       " 'Why',\n",
       " 'the',\n",
       " 'edits',\n",
       " 'made',\n",
       " 'under',\n",
       " 'my',\n",
       " 'username',\n",
       " 'Hardcore',\n",
       " 'Metallica',\n",
       " 'Fan',\n",
       " 'were',\n",
       " 'reverted',\n",
       " '?',\n",
       " 'They',\n",
       " 'were',\n",
       " \"n't\",\n",
       " 'vandalisms',\n",
       " ',',\n",
       " 'just',\n",
       " 'closure',\n",
       " 'on',\n",
       " 'some',\n",
       " 'GAs',\n",
       " 'after',\n",
       " 'I',\n",
       " 'voted',\n",
       " 'at',\n",
       " 'New',\n",
       " 'York',\n",
       " 'Dolls',\n",
       " 'FAC',\n",
       " '.',\n",
       " 'And',\n",
       " 'please',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'remove',\n",
       " 'the',\n",
       " 'template',\n",
       " 'from',\n",
       " 'the',\n",
       " 'talk',\n",
       " 'page',\n",
       " 'since',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'retired',\n",
       " 'now.89.205.38.27']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenize 分词,中文可用corenlp或者jieba，kaggle的dockerimage中无\n",
    "sentence = list_sentences_train[0]\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['explanation', 'why', 'the', 'edits', 'made', 'under', 'my', 'username', 'hardcore', 'metallica', 'fan', 'were', 'reverted', '?', 'they', \"weren't\", 'vandalisms', ',', 'just', 'closure', 'on', 'some', 'gas', 'after', 'i', 'voted', 'at', 'new', 'york', 'dolls', 'fac', '.', 'and', 'please', \"don't\", 'remove', 'the', 'template', 'from', 'the', 'talk', 'page', 'since', \"i'm\", 'retired', 'now', '.', '89.205', '.', '38.27']\n"
     ]
    }
   ],
   "source": [
    "import re #正则表达式\n",
    "emoticons_str = r\"\"\"     \n",
    "    (?:     [:=;] # 眼睛        \n",
    "            [oO\\-]? # ⿐⼦        \n",
    "            [D\\)\\]\\(\\]/\\\\OpP] # 嘴    \n",
    "    )\"\"\" \n",
    "\n",
    "regex_str = [emoticons_str,\n",
    "             r'<[^>]+>', # HTML tags     \n",
    "             r'(?:@[\\w_]+)', # @某⼈    \n",
    "             r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # 话题标签    \n",
    "             r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+',# URLs     \n",
    "             r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # 数字    \n",
    "             r\"(?:[a-z][a-z'\\-_]+[a-z])\", # 含有 - 和 ‘ 的单词    \n",
    "             r'(?:[\\w_]+)', # 其他    \n",
    "             r'(?:\\S)' # 其他\n",
    "            ]\n",
    "\n",
    "\n",
    "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE) \n",
    "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
    "\n",
    "def tokenize(s):     \n",
    "    return tokens_re.findall(s)  \n",
    "\n",
    "def preprocess(s, lowercase=True):     \n",
    "    tokens = tokenize(s)     \n",
    "    if lowercase:         \n",
    "        tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]     \n",
    "    return tokens  \n",
    "     \n",
    "print(preprocess(sentence)) #nice work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'went'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if corpus is not big enough\n",
    "# we need stemming or lemmatization 2 narrow our data scale like went -> go\n",
    "from nltk.stem.porter import PorterStemmer \n",
    "porter_stemmer = PorterStemmer() \n",
    "porter_stemmer.stem('maximum')\n",
    "porter_stemmer.stem('presumably')\n",
    "porter_stemmer.stem('multiply')\n",
    "porter_stemmer.stem('provision')\n",
    "\n",
    "from nltk.stem import SnowballStemmer #genghaoyongyixie\n",
    "snowball_stemmer = SnowballStemmer(\"english\")\n",
    "snowball_stemmer.stem('wenting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "wordnet_lemmatizer.lemmatize('went', pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('explanation', 'NN'),\n",
       " ('why', 'WRB'),\n",
       " ('the', 'DT'),\n",
       " ('edits', 'NNS'),\n",
       " ('made', 'VBN'),\n",
       " ('under', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('username', 'JJ'),\n",
       " ('hardcore', 'NN'),\n",
       " ('metallica', 'NN'),\n",
       " ('fan', 'NN'),\n",
       " ('were', 'VBD'),\n",
       " ('reverted', 'VBN'),\n",
       " ('?', '.'),\n",
       " ('they', 'PRP'),\n",
       " (\"weren't\", 'VBP'),\n",
       " ('vandalisms', 'NNS'),\n",
       " (',', ','),\n",
       " ('just', 'RB'),\n",
       " ('closure', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('some', 'DT'),\n",
       " ('gas', 'NN'),\n",
       " ('after', 'IN'),\n",
       " ('i', 'NN'),\n",
       " ('voted', 'VBD'),\n",
       " ('at', 'IN'),\n",
       " ('new', 'JJ'),\n",
       " ('york', 'NN'),\n",
       " ('dolls', 'NNS'),\n",
       " ('fac', 'VBP'),\n",
       " ('.', '.'),\n",
       " ('and', 'CC'),\n",
       " ('please', 'VB'),\n",
       " (\"don't\", 'JJ'),\n",
       " ('remove', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('template', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('talk', 'NN'),\n",
       " ('page', 'NN'),\n",
       " ('since', 'IN'),\n",
       " (\"i'm\", 'NN'),\n",
       " ('retired', 'VBN'),\n",
       " ('now', 'RB'),\n",
       " ('.', '.'),\n",
       " ('89.205', 'CD'),\n",
       " ('.', '.'),\n",
       " ('38.27', 'CD')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postagtest = preprocess(sentence)\n",
    "nltk.pos_tag(postagtest)#判断词性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['explanation',\n",
       " 'edits',\n",
       " 'made',\n",
       " 'username',\n",
       " 'hardcore',\n",
       " 'metallica',\n",
       " 'fan',\n",
       " 'reverted',\n",
       " '?',\n",
       " 'vandalisms',\n",
       " ',',\n",
       " 'closure',\n",
       " 'gas',\n",
       " 'voted',\n",
       " 'new',\n",
       " 'york',\n",
       " 'dolls',\n",
       " 'fac',\n",
       " '.',\n",
       " 'please',\n",
       " 'remove',\n",
       " 'template',\n",
       " 'talk',\n",
       " 'page',\n",
       " 'since',\n",
       " \"i'm\",\n",
       " 'retired',\n",
       " '.',\n",
       " '89.205',\n",
       " '.',\n",
       " '38.27']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stop words 去除He，The，it这些东西 会破坏句式结构\n",
    "from nltk.corpus import stopwords\n",
    "filtered_words = [word for word in preprocess(sentence) if word not in stopwords.words('english')]\n",
    "filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#w2v\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
